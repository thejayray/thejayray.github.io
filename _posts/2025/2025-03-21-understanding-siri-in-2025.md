---
layout: post
date: 2025-03-21 11:15:00 -0500
tags: post, technology, ai, support
title: Understanding Siri in 2025
---

**Key takeaways:**
* Siri used to always work for the things that mattered most to me.
* With the pivot from machine learning to AI, Apple has shifted even a technologists' viewpoints of understanding what Siri is able to do.
* I understand the technology behind both machine learning and current generative AI models and I still don't know how to help Siri do what I need it to do since Apple Intelligence.
* LLMs were intended to make Siri more flexible, but may have made it simply more obtuse.
* I kinda want old "dumb" Siri back.

---

As a technologist by trade and an engineer at heart, I work hard to and pride myself on understanding how things work. In particular, in the area of technology, I have worked tirelessly over the years to understand the technology landscape and put that knowledge to use playing with it, writing about it, and supporting those around me in their use of it.

This has also helped me to understand that I am what used to be referred to as "a software person", which means that I had a penchant for and the ability to figure out new softwares with relative ease in comparison to my peers. I would personally say that I have known this to be true especially in situations in which I understand the purpose of the piece of software and it is logically (perhaps better said naturally or in alignment with commons norms) laid out and/or well-designed.

There are pieces of software that "just work" (to use Apple's parlance) for me (as a software person) and there are those that "just work" for everyone. Regardless of how you have felt about Siri's foibles or inabilities in the past or the jokes made at Siri's expense, I personally believe that it largely worked as expected. In the past, I was able to figure out how to phrase requests to get what I wanted and those I couldn't were extensible or able to be added by using Shortcuts and similar integrations.

To top this all off, I felt like I understood how Siri worked, how to manipulate it to work for me in situations where it didn't, and how to help others to navigate it to get the most out of it.

Not to pile onto [the coverage](https://daringfireball.net/2025/03/something_is_rotten_in_the_state_of_cupertino) of all the things going on with Apple's Siri digital assistant and Apple Intelligence, but I was just saying to my wife this morning that I don't feel like I understand how the tool works anymore. I think the harder thing here is the fact that I used to understand how it worked and I understand how LLMs work, but now when I ask Siri to do things that it used to do without hesitation or things I had manipulated it to do, it no longer does those things.

This all comes to a head when my wife makes a simple call to CarPlay Siri: "take me to my husband's work." This is an easy request in the Siri of old and it was extensible, so that if the "husband" association or the "work" association changed, it would know that. This is how Siri used to work around these types of requests:
1. In my wife's phone, she has a contact for me.
2. In that contact, she has created the association that I am her husband and I have two different addresses: home and work.
3. Asking Siri to direct her to one of those locations could be called up by asking for directions or requests to "take me to" a specific location; in these situations, she could use my name (first and last or even just first name) or my role (husband) and the label of the location (home or work or garage or whatever).
4. End of list.

New Siri started falling down at the point when I added a drop-off location to my contact card. In the past, I would have added this and she would have been about to say "take me to my husband's drop-off" or something similar and it would have just worked. But now, we have noted that Siri will accept no other phrasing than "take me to my husband's work." She cannot use my name, the specific contact card name, nor an additional labelled location. My wife can't do it in multiple steps either, e.g. "show me Jay's locations" and then "take me to drop-off".

Oddly, though, Siri (used to not be good at and) can now accept "take me to Jay Ray's location" (since it is shared) and it will find me in that moment and set the directions. That is useful only if I am waiting for my wife at that specific location, though, an admittedly rare occurrence for us because I am waiting "at work" or I am on the move and we are meeting somewhere (like my %&@#! contact-card-enabled drop-off point).

In hindsight, these misses began as soon as iOS 18 shipped, wherein we would tell Siri to take us to specific cross-streets and it was suddenly very rigid about how we phrased the names of each street ("Park Street" wouldn't work, but "South Park Street" would). What is perhaps most odd about this is the notion that the updates to Siri were in the name of making it more malleable and extensible, not less. However, because LLMs are intentionally designed to be engines that run on probabilistic luck (i.e. stringing random mathematically logical words together to make sentences), it is decidedly plausible that the very thing that was intended to make Siri more flexible has actually made it simply more obtuse.

Say what you will about Siri then and now, but I hope that Apple sees the outcomes of these recent changes and decides on their own path (a think different one, perhaps), instead of the one that every other company investing in generative AI is choosing. I never thought I would ask for old Siri back, but (call me crazy) I kinda am right now.